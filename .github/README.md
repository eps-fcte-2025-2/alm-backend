# ALM - xLSTM Service

Servi√ßo de infer√™ncia para Asset Liability Management (ALM) utilizando modelos xLSTM (extended Long Short-Term Memory) para previs√£o de pre√ßos de ativos. O Backend da Plataforma ALM √© o servi√ßo central do projeto. Por fim, o trabalho deste repost√≥rio foi realizado durante a disciplina EPS (Engenharia de Produto de Software) do semestre 25.2 (UnB - FCTE) e corresponde ao trabalho do Grupo 11, orientado pelo professor Ricardo Matos Chaim.

## Equipe

| Nome                              | Matr√≠cula   | Papel                              |
| --------------------------------- | ----------- | ---------------------------------- |
| Ricardo Matos Chaim               | 39742059187 | Product Owner e Orientador         |
| Thomas Queiroz Souza Alves        | 211062526   | Gerente de projeto e Desenvolvedor |
| Andr√© Emanuel Bispo da Silva      | 221007813   | Desenvolvedor                      |
| Artur Henrique Holz Bartz         | 221007869   | Desenvolvedor                      |
| Eduardo Matheus dos Santos Sandes | 221008024   | Desenvolvedor                      |

## √çndice

- [Sobre o Projeto](#sobre-o-projeto)
- [Tecnologias Utilizadas](#tecnologias-utilizadas)
- [Estrutura do Projeto](#estrutura-do-projeto)
- [Pr√©-requisitos](#pr√©-requisitos)
- [Instala√ß√£o e Execu√ß√£o](#instala√ß√£o-e-execu√ß√£o)
- [Endpoints da API](#endpoints-da-api)
- [Exemplos de Uso](#exemplos-de-uso)
- [Formato dos Dados](#formato-dos-dados)
- [Desenvolvimento](#desenvolvimento)

## Sobre o Projeto

Este servi√ßo fornece uma API REST para realizar infer√™ncias com modelos xLSTM treinados. O sistema processa arquivos CSV contendo embeddings de s√©ries temporais financeiras e retorna previs√µes de pre√ßos futuros.

### Caracter√≠sticas Principais

- **Processamento Ass√≠ncrono**: Jobs s√£o enfileirados e processados em background
- **M√∫ltiplos Modelos**: Suporte para carregar e utilizar diferentes modelos treinados
- **Detec√ß√£o Autom√°tica de GPU**: Utiliza CUDA, MPS ou CPU automaticamente
- **API RESTful**: Interface padronizada e documentada
- **Containeriza√ß√£o**: Totalmente dockerizado para f√°cil deployment

## Tecnologias Utilizadas

- **FastAPI**: Framework web moderno e r√°pido
- **PyTorch**: Framework de deep learning
- **xLSTM**: Arquitetura de rede neural recorrente avan√ßada
- **Docker & Docker Compose**: Containeriza√ß√£o
- **Uvicorn**: Servidor ASGI de alta performance
- **Pydantic**: Valida√ß√£o de dados
- **Pandas & NumPy**: Processamento de dados

## Estrutura do Projeto

```
src/
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ main.py                      # Aplica√ß√£o principal FastAPI
‚îÇ   ‚îú‚îÄ‚îÄ routers/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ inference.py             # Endpoints de infer√™ncia
‚îÇ   ‚îú‚îÄ‚îÄ schemas/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ inference.py             # Modelos Pydantic (request/response)
‚îÇ   ‚îî‚îÄ‚îÄ services/
‚îÇ       ‚îî‚îÄ‚îÄ inference_service.py     # L√≥gica de neg√≥cio e processamento
‚îú‚îÄ‚îÄ models/                          # Diret√≥rio para modelos PyTorch (.pt)
‚îú‚îÄ‚îÄ submodules/
‚îÇ   ‚îî‚îÄ‚îÄ PyxLSTM/                     # Subm√≥dulo com implementa√ß√£o xLSTM
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ conftest.py
‚îÇ   ‚îî‚îÄ‚îÄ test_itens.py
‚îú‚îÄ‚îÄ .env.dev                         # Vari√°veis de ambiente
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ pyproject.toml                   # Configura√ß√µes de formata√ß√£o
‚îî‚îÄ‚îÄ requirements.txt                 # Depend√™ncias Python
```

## Pr√©-requisitos

- Docker 20.10+
- Docker Compose 2.0+
- Subm√≥dulo PyxLSTM importado
- (Opcional) NVIDIA Docker para suporte GPU

## Instala√ß√£o e Execu√ß√£o

### 1. Clone o Reposit√≥rio

```bash
git clone <url-do-repositorio>
cd <nome-do-repositorio>
```

### 2. Importe o Subm√≥dulo PyxLSTM

```bash
git submodule update --init --recursive
```

### 3. Prepare os Modelos

Coloque seus modelos PyTorch treinados (arquivos `.pt`) no diret√≥rio `src/models/`:

```bash
mkdir -p src/models
cp seu_modelo.pt src/models/
```

**Formato esperado do modelo:**
- Arquivo `.pt` contendo um checkpoint com:
  - `model_state_dict`: pesos do modelo
  - `config`: configura√ß√£o do modelo (input_size, hidden_size, etc.)

### 4. Configure as Vari√°veis de Ambiente

O arquivo `.env.dev` j√° est√° configurado com valores padr√£o. Ajuste se necess√°rio:

```env
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres
POSTGRES_DB=fastapi_db
POSTGRES_HOST=db
POSTGRES_PORT=5432
```

### 5. Inicie os Containers

```bash
cd src
docker-compose up --build
```

O servi√ßo estar√° dispon√≠vel em: `http://localhost:8000`

### 6. Verifique o Status

```bash
curl http://localhost:8000/health
```

Resposta esperada:
```json
{"status": "healthy"}
```

## üîå Endpoints da API

### 1. Health Check

**GET** `/health`

Verifica se o servi√ßo est√° funcionando.

**Resposta:**
```json
{
  "status": "healthy"
}
```

### 2. Listar Modelos Dispon√≠veis

**GET** `/api/v1/models`

Lista todos os modelos PyTorch dispon√≠veis no diret√≥rio `models/`.

**Resposta:**
```json
{
  "models": [
    {
      "name": "petr_4_xlstm_embedding_128",
      "path": "models/petr_4_xlstm_embedding_128.pt",
      "config": {
        "input_size": 128,
        "hidden_size": 256,
        "num_layers": 3,
        "num_blocks": 7,
        "output_size": 1,
        "dropout": 0.1,
        "prediction_horizon": 5
      },
      "loaded": false
    }
  ]
}
```

### 3. Submeter Job de Infer√™ncia

**POST** `/api/v1/inference/{model_name}`

Submete um arquivo CSV para processamento ass√≠ncrono.

**Par√¢metros:**
- `model_name` (path): Nome do modelo a ser utilizado
- `file` (form-data): Arquivo CSV com os dados

**Exemplo:**
```bash
curl -X POST "http://localhost:8000/api/v1/inference/petr_4_xlstm_embedding_128" \
     -F "file=@dados.csv"
```

**Resposta (202 Accepted):**
```json
{
  "job_id": "550e8400-e29b-41d4-a716-446655440000",
  "status": "pending",
  "model": "petr_4_xlstm_embedding_128",
  "message": "CSV file 'dados.csv' uploaded and queued for processing. Use job_id to retrieve results."
}
```

### 4. Consultar Resultado

**GET** `/api/v1/result/{job_id}`

Recupera o resultado de um job de infer√™ncia.

**Exemplo:**
```bash
curl "http://localhost:8000/api/v1/result/550e8400-e29b-41d4-a716-446655440000"
```

**Resposta (Job Pendente):**
```json
{
  "job_id": "550e8400-e29b-41d4-a716-446655440000",
  "status": "pending",
  "submitted_at": "2024-12-04T10:30:00.000Z",
  "completed_at": null,
  "model": "petr_4_xlstm_embedding_128",
  "result": null,
  "error": null
}
```

**Resposta (Job Completo):**
```json
{
  "job_id": "550e8400-e29b-41d4-a716-446655440000",
  "status": "completed",
  "submitted_at": "2024-12-04T10:30:00.000Z",
  "completed_at": "2024-12-04T10:30:15.000Z",
  "model": "petr_4_xlstm_embedding_128",
  "result": {
    "predicted_prices": [25.34, 25.67, 25.89, 26.12, 26.45],
    "prediction_horizon": 5,
    "current_price": 25.10
  },
  "error": null
}
```

**Resposta (Job com Erro):**
```json
{
  "job_id": "550e8400-e29b-41d4-a716-446655440000",
  "status": "failed",
  "submitted_at": "2024-12-04T10:30:00.000Z",
  "completed_at": "2024-12-04T10:30:10.000Z",
  "model": "petr_4_xlstm_embedding_128",
  "result": null,
  "error": "Not enough data points. Need at least 20, got 15"
}
```

## Formato dos Dados

### Arquivo CSV de Entrada

O arquivo CSV deve conter as seguintes colunas:

- `emb_0` at√© `emb_127`: 128 colunas de embeddings (valores float)
- `last_price`: Pre√ßo atual do ativo (valor float)

**Exemplo:**

```csv
emb_0,emb_1,emb_2,...,emb_127,last_price
0.123,0.456,0.789,...,0.321,25.10
0.234,0.567,0.890,...,0.432,25.15
...
```

**Requisitos:**
- M√≠nimo de 20 linhas (tamanho da sequ√™ncia)
- Todas as colunas de embedding devem estar presentes
- Valores num√©ricos v√°lidos
- Codifica√ß√£o UTF-8

## Desenvolvimento

### Executar Testes

```bash
docker-compose exec web pytest
```

### Verificar Cobertura de Testes

```bash
docker-compose exec web pytest --cov=app --cov-report=html
```

### Formata√ß√£o de C√≥digo

O projeto utiliza Black e Ruff para formata√ß√£o e linting.

```bash
# Formatar c√≥digo
docker-compose exec web black .

# Verificar linting
docker-compose exec web ruff check .
```

### Logs do Container

```bash
docker-compose logs -f web
```

### Acessar Container

```bash
docker-compose exec web bash
```

### Parar os Servi√ßos

```bash
docker-compose down
```

### Parar e Remover Volumes

```bash
docker-compose down -v
```

## Configura√ß√µes Avan√ßadas

### Vari√°veis de Ambiente

| Vari√°vel | Descri√ß√£o | Padr√£o |
|----------|-----------|--------|
| `POSTGRES_USER` | Usu√°rio do PostgreSQL | `postgres` |
| `POSTGRES_PASSWORD` | Senha do PostgreSQL | `postgres` |
| `POSTGRES_DB` | Nome do banco de dados | `fastapi_db` |
| `POSTGRES_HOST` | Host do PostgreSQL | `db` |
| `POSTGRES_PORT` | Porta do PostgreSQL | `5432` |

### Configura√ß√£o do Modelo

Os modelos devem ter a seguinte configura√ß√£o no checkpoint:

```python
config = {
    "input_size": 128,          # Tamanho do embedding de entrada
    "hidden_size": 256,         # Tamanho da camada oculta
    "num_layers": 3,            # N√∫mero de camadas xLSTM
    "num_blocks": 7,            # N√∫mero de blocos por camada
    "output_size": 1,           # Tamanho da sa√≠da
    "dropout": 0.1,             # Taxa de dropout
    "prediction_horizon": 5     # Horizonte de previs√£o
}
```

## Documenta√ß√£o Interativa

Ap√≥s iniciar o servi√ßo, acesse a documenta√ß√£o interativa:

- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

## Licen√ßa

Este projeto est√° sob a licen√ßa especificada no arquivo LICENSE.

---

**Nota**: Este √© um servi√ßo de infer√™ncia. Para treinar novos modelos, consulte a documenta√ß√£o do PyxLSTM.
